{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "37puETfgRzzg"
      },
      "source": [
        "# Data Preprocessing Tools"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "EoRP98MpR-qj"
      },
      "source": [
        "## Importing the libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "N-qiINBQSK2g"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "RopL7tUZSQkT"
      },
      "source": [
        "## Importing the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "WwEPNDWySTKm"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "資料\n",
            "[['France' 44.0 72000.0]\n",
            " ['Spain' 27.0 48000.0]\n",
            " ['Germany' 30.0 54000.0]\n",
            " ['Spain' 38.0 61000.0]\n",
            " ['Germany' 40.0 nan]\n",
            " ['France' 35.0 58000.0]\n",
            " ['Spain' nan 52000.0]\n",
            " ['France' 48.0 79000.0]\n",
            " ['Germany' 50.0 83000.0]\n",
            " ['France' 37.0 67000.0]]\n",
            "標籤\n",
            "['No' 'Yes' 'No' 'No' 'Yes' 'Yes' 'No' 'Yes' 'No' 'Yes']\n"
          ]
        }
      ],
      "source": [
        "dataset = pd.read_csv('Data.csv')\n",
        "X = dataset.iloc[:, :-1].values\n",
        "y = dataset.iloc[:, -1].values\n",
        "\n",
        "print(\"資料\")\n",
        "print(X)\n",
        "print(\"標籤\")\n",
        "print(y)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "nhfKXNxlSabC"
      },
      "source": [
        "## 處理遺失值"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "c93k7ipkSexq"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[44.0, 72000.0],\n",
              "       [27.0, 48000.0],\n",
              "       [30.0, 54000.0],\n",
              "       [38.0, 61000.0],\n",
              "       [40.0, 63777.77777777778],\n",
              "       [35.0, 58000.0],\n",
              "       [38.77777777777778, 52000.0],\n",
              "       [48.0, 79000.0],\n",
              "       [50.0, 83000.0],\n",
              "       [37.0, 67000.0]], dtype=object)"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.impute import SimpleImputer\n",
        "imputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
        "# missing_values=np.nan：指定缺失值的表示方式為 np.nan（即 NumPy 中的空值）。\n",
        "# strategy='mean'：指定填補缺失值的策略為均值（mean）。這意味著所有的缺失值將被所在列的平均值替換。\n",
        "\n",
        "imputer.fit(X[:, 1:3])\n",
        "# 對數據集 X 的第 1 列和第 2 列（注意 Python 中的索引從 0 開始）進行擬合（fit）。也就是說，計算這些列的均值，以便之後用這些均值替換缺失值。\n",
        "X[:, 1:3] = imputer.transform(X[:, 1:3])\n",
        "\n",
        "X[:, 1:3]\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "CriG6VzVSjcK"
      },
      "source": [
        "## 將資料進行熱處理"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "AhSpdQWeSsFh"
      },
      "source": [
        "### Encoding the Independent Variable"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "5hwuVddlSwVi"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[0.0 1.0 0.0 1.0 0.0 0.0 44.0 72000.0]\n",
            " [1.0 0.0 1.0 0.0 0.0 1.0 27.0 48000.0]\n",
            " [1.0 0.0 1.0 0.0 1.0 0.0 30.0 54000.0]\n",
            " [1.0 0.0 1.0 0.0 0.0 1.0 38.0 61000.0]\n",
            " [1.0 0.0 1.0 0.0 1.0 0.0 40.0 63777.77777777778]\n",
            " [0.0 1.0 0.0 1.0 0.0 0.0 35.0 58000.0]\n",
            " [1.0 0.0 1.0 0.0 0.0 1.0 38.77777777777778 52000.0]\n",
            " [0.0 1.0 0.0 1.0 0.0 0.0 48.0 79000.0]\n",
            " [1.0 0.0 1.0 0.0 1.0 0.0 50.0 83000.0]\n",
            " [0.0 1.0 0.0 1.0 0.0 0.0 37.0 67000.0]]\n",
            "[0 1 0 0 1 1 0 1 0 1]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "# 處理自變數\n",
        "ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [0])], remainder='passthrough')\n",
        "X = np.array(ct.fit_transform(X))\n",
        "\n",
        "# 處理依變數：針對標籤進行編碼\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "le = LabelEncoder()\n",
        "y = le.fit_transform(y)\n",
        "\n",
        "print(X)\n",
        "print(y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "qb_vcgm3qZKW"
      },
      "source": [
        "## 拆分資料訓練與測試集"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "pXgA6CzlqbCl"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "資料訓練集\n",
            "[[1.0 0.0 1.0 0.0 1.0 0.0 30.0 54000.0]\n",
            " [0.0 1.0 0.0 1.0 0.0 0.0 37.0 67000.0]]\n",
            "標籤訓練集\n",
            "[0 1 0 0 1 1 0 1]\n"
          ]
        }
      ],
      "source": [
        "# 將資料拆成兩成測試八成訓練\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 1)\n",
        "\n",
        "print(\"資料訓練集\")\n",
        "print(X_test)\n",
        "print(\"標籤訓練集\")\n",
        "print(y_train)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "TpGqbS4TqkIR"
      },
      "source": [
        "## Feature Scaling\n",
        "- 將資料的值進行逼準化。\n",
        "- 標準化將數據轉換為均值為 0，標準差為 1 的分佈，有助於提高模型的性能和收斂速度，尤其是對於使用梯度下降優化的算法（例如，線性回歸和神經網絡）。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "AxjSUXFQqo-3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "將年齡進行逼準化\n",
            "[[1.0 0.0 1.0 -0.7745966692414834 -0.5773502691896258 1.2909944487358056\n",
            "  -0.19159184384578545 -1.0781259408412425]\n",
            " [1.0 0.0 1.0 -0.7745966692414834 1.7320508075688774 -0.7745966692414834\n",
            "  -0.014117293757057777 -0.07013167641635372]\n",
            " [0.0 1.0 0.0 1.2909944487358056 -0.5773502691896258 -0.7745966692414834\n",
            "  0.566708506533324 0.633562432710455]\n",
            " [1.0 0.0 1.0 -0.7745966692414834 -0.5773502691896258 1.2909944487358056\n",
            "  -0.30453019390224867 -0.30786617274297867]\n",
            " [1.0 0.0 1.0 -0.7745966692414834 -0.5773502691896258 1.2909944487358056\n",
            "  -1.9018011447007988 -1.420463615551582]\n",
            " [0.0 1.0 0.0 1.2909944487358056 -0.5773502691896258 -0.7745966692414834\n",
            "  1.1475343068237058 1.232653363453549]\n",
            " [1.0 0.0 1.0 -0.7745966692414834 1.7320508075688774 -0.7745966692414834\n",
            "  1.4379472069688968 1.5749910381638885]\n",
            " [0.0 1.0 0.0 1.2909944487358056 -0.5773502691896258 -0.7745966692414834\n",
            "  -0.7401495441200351 -0.5646194287757332]]\n",
            "[[1.0 0.0 1.0 -0.7745966692414834 1.7320508075688774 -0.7745966692414834\n",
            "  -1.4661817944830124 -0.9069571034860727]\n",
            " [0.0 1.0 0.0 1.2909944487358056 -0.5773502691896258 -0.7745966692414834\n",
            "  -0.44973664397484414 0.2056403393225306]]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "sc = StandardScaler()\n",
        "\n",
        "# 第三列（年齡）進行標準化\n",
        "X_train[:, 3:] = sc.fit_transform(X_train[:, 3:])\n",
        "X_test[:, 3:] = sc.transform(X_test[:, 3:])\n",
        "\n",
        "print(\"將年齡進行逼準化\")\n",
        "print(X_train)\n",
        "print(X_test)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "data_preprocessing_tools.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
